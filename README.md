
# Mitigating Biased Legal Judgment Prediction using Adversarial Debiasing

## Overview

This project explores how to reduce bias in AI-based legal judgment prediction models using Adversarial Debiasing techniques integrated with IBMâ€™s AI Fairness 360 (AIF360) toolkit. The goal is to ensure fairness, accountability, and transparency in automated judicial decision-making systems.

## Problem Statement
AI models like COMPAS have shown biased predictions in judicial contexts, especially along racial and gender lines. This project proposes a fairness-aware machine learning pipeline to reduce such biases while maintaining high predictive accuracy.

## Ethical and Legal Impact
Ensures statistical and discursive fairness in AI-augmented legal systems.

Supports regulatory compliance and trust in automated decision-making.

Encourages inclusive development and legal accountability.

## Results
Debiasing Effectiveness: Bias significantly reduced across training and test datasets.

Trade-off Analysis: Fairness improved with moderate impact on model accuracy.

Post-Processing Gains: Equal opportunity difference reduced drastically with minimal loss in balanced accuracy.


